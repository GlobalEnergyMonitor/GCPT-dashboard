{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aae4258a-ac01-4e26-a282-bd5dad2b776e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# key parameters\n",
    "gcpt_dash_file = 'GCPT dashboard data 2023-02.xlsx'\n",
    "gcpt_dash_path = '/Users/masoninman/Dropbox/GEM/Global Coal Plant Tracker/GCPT Dash/'\n",
    "\n",
    "# max_year = 2022"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99bde4fa-395e-4898-999e-b47872470c58",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import time\n",
    "from pandas.api.types import CategoricalDtype\n",
    "import pygsheets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6d08b97-7366-4803-90ef-848603e99cc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "gcpt_dash_xl = pd.ExcelFile(gcpt_dash_path + gcpt_dash_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3711594",
   "metadata": {},
   "outputs": [],
   "source": [
    "def determine_max_year(gcpt_dash_file):\n",
    "    yyyy_mm = gcpt_dash_file.split('.xlsx')[0].split(' ')[-1]\n",
    "    month_int = int(yyyy_mm.split('-')[-1])\n",
    "    year_int = int(yyyy_mm.split('-')[0])\n",
    "    if month_int < 6:\n",
    "        max_year = year_int - 1\n",
    "    else:\n",
    "        max_year = year_int\n",
    "        \n",
    "    # print(f\"max_year: {max_year}\")\n",
    "\n",
    "    return max_year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3ded14c-1c24-4a9d-95b9-2c0b07b9bfe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create list of countries to choose from (GEM country names)\n",
    "# data in gcpt_status is most complete; example of Albania, which only has cancelled units, nothing else\n",
    "max_year = determine_max_year(gcpt_dash_file)\n",
    "gcpt_status_orig = pd.read_excel(gcpt_dash_xl, sheet_name = f'2014-{max_year}')\n",
    "gcpt_country_list = gcpt_status_orig['Country'].sort_values().unique().tolist()\n",
    "gcpt_country_list = ['all'] + gcpt_country_list"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6dcaae99-e115-4835-99c6-6ec200e2b787",
   "metadata": {},
   "source": [
    "## Map (upper left)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a469d15-0f81-44c9-b6df-4e19ea1addf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_country_code_df():\n",
    "    # TO DO: change below to draw from GEM's country list, which also includes the ISO names\n",
    "    # \"GEM Naming Conventions - Countries & subdivisions\"\n",
    "    # https://docs.google.com/spreadsheets/d/1mtlwSJfWy1gbIwXVgpP3d6CcUEWo2OM0IvPD6yztGXI/edit#gid=0\n",
    "\n",
    "    country_codes_file = 'List of ISO 3166 country codes (Wikipedia).xlsx'\n",
    "    country_codes_path = '/Users/masoninman/Dropbox/GEM/'\n",
    "    country_codes = pd.read_excel(country_codes_path + country_codes_file)\n",
    "\n",
    "    # clean up the codes to remove non-printing characters from wikipedia\n",
    "    for col in country_codes.columns:\n",
    "        if country_codes[col].dtype == object:\n",
    "            country_codes[col] = country_codes[col].str.replace('\\xa0', '', regex=False)\n",
    "\n",
    "    # get rid of parenthetical footnotes at end of names & whitespace\n",
    "    country_codes['Country name (ISO 3166)'] = country_codes['Country name (ISO 3166)'].str.split('[').str[0].str.strip()\n",
    "\n",
    "    return country_codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ec8b80d-6359-4a6a-84f6-7e1cf8ca4268",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_country_name_conversions_dict():\n",
    "    \"\"\"\n",
    "    Creates a dictionary for converting GEM standard country names to ISO 3166 versions.\n",
    "    \n",
    "    This downloads the GEM standard names file from Google Sheets using pygsheets,\n",
    "    then pares down the df to only those in which GEM uses a different name than ISO 3166.\n",
    "\n",
    "    Then it creates a dictionary, which can be used for converting from GEM to ISO.\n",
    "    \n",
    "    This is needed because Plotly's choropleth function uses ISO names for getting the outline for each country.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Google access code for using pysheets\n",
    "    # (requires connecting on Google Cloud Platform, and also a secret code saved locally)\n",
    "    client_secret = 'client_secret_494167307270-j1830ren871hm4of1rt1n3c7gv7vo7aa.apps.googleusercontent.com.json'\n",
    "\n",
    "    standard_country_names_key = '1mtlwSJfWy1gbIwXVgpP3d6CcUEWo2OM0IvPD6yztGXI'\n",
    "\n",
    "    gc = pygsheets.authorize('/Users/masoninman/' + client_secret)\n",
    "    gsheet = gc.open_by_key(standard_country_names_key)\n",
    "    df = gsheet.worksheet('title', 'Countries').get_as_df()\n",
    "    \n",
    "    # keep only those with a mismatch\n",
    "    name_diffs = df.copy()\n",
    "    name_diffs = name_diffs[name_diffs['GEM name same as ISO 3166?']=='FALSE']\n",
    "    # exclude those not in ISO\n",
    "    name_diffs = name_diffs[name_diffs['ISO 3166 Country Name']!='NOT LISTED']\n",
    "    name_diffs_dict = name_diffs.set_index('GEM Standard Country Name')['ISO 3166 Country Name'].to_dict()   \n",
    "    \n",
    "    return name_diffs_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d24c87a2-5af0-4a17-94cf-f5ac19e19245",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get map df\n",
    "gcpt_map = pd.read_excel(gcpt_dash_xl, sheet_name = 'Map')\n",
    "gcpt_map = gcpt_map.rename(columns={'Total operating Capacity': 'Capacity (MW)'})\n",
    "\n",
    "# add any missing countries, to make sure that all countries in gcpt_country_list are in gcpt_map\n",
    "missing_countries = [x for x in gcpt_country_list if x not in gcpt_map['Country'].tolist()]\n",
    "if len(missing_countries) > 0:\n",
    "    print(f\"These countries were missing: {missing_countries}\")\n",
    "    missing_df = pd.DataFrame.from_dict({\n",
    "            'Country': missing_countries, \n",
    "            'Capacity (MW)': [float(0)]*len(missing_countries)\n",
    "        }, orient='columns')\n",
    "    gcpt_map = pd.concat([gcpt_map, missing_df], sort=False)\n",
    "\n",
    "# change GEM country names to ISO 3166\n",
    "name_diffs_dict = create_country_name_conversions_dict()\n",
    "gcpt_map['Country name (ISO 3166)'] = gcpt_map['Country'].replace(name_diffs_dict)\n",
    "\n",
    "# Note: Kosovo isn't recognized in ISO 3166, so can't be shown on Plotly map on its own. \n",
    "# We could combine it with Serbia for display--but then our data in the dashboard wouldn't be the same as in our spreadsheets & other maps.\n",
    "# Wikipedia said Kosovo declared independence from Serbia in 2008; it is only partially recognized.\n",
    "\n",
    "# show countries in gcpt_map not in gcpt_country_list:\n",
    "extraneous_countries = [x for x in gcpt_map['Country'].tolist() if x not in gcpt_country_list]\n",
    "if len(extraneous_countries) > 0:\n",
    "    print(f\"Extraneous countries to be removed: {extraneous_countries}\")\n",
    "\n",
    "# keep only countries that are in gcpt_country_list\n",
    "gcpt_map = gcpt_map[gcpt_map['Country'].isin(gcpt_country_list)]\n",
    "\n",
    "# merge in ISO country codes (needed by Plotly)\n",
    "country_codes = create_country_code_df()\n",
    "gcpt_map = pd.merge(\n",
    "    country_codes[['Country name (ISO 3166)', 'Alpha-3 code (ISO 3166-1)']],\n",
    "    gcpt_map,\n",
    "    on='Country name (ISO 3166)', \n",
    "    how='outer'\n",
    ")\n",
    "gcpt_map = gcpt_map.rename(columns={'Alpha-3 code (ISO 3166-1)': 'iso_alpha'})\n",
    "\n",
    "# exclude those with no value for iso_alpha\n",
    "# This excludes notes within the ISO dataset, e.g., \"Akrotiri and Dhekelia â€“ See United Kingdom, The.\"\n",
    "# Unfortunately, this also excludes Kosovo from GCPT\n",
    "gcpt_map = gcpt_map[gcpt_map['iso_alpha'].isna()==False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a03e7b24-02d4-48b3-8212-bcd6ceeebad7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if capacity is 0, instead use 1, to avoid zero capacity leading to -inf log value\n",
    "# similar approach is used in numpy log1p\n",
    "# https://numpy.org/doc/stable/reference/generated/numpy.log1p.html\n",
    "gcpt_map['capacity log10 + 1'] = np.log10(gcpt_map['Capacity (MW)'].replace(float(0), float(1)))\n",
    "\n",
    "# create hover text\n",
    "# (note: variable hover_text below is a Pandas Series)\n",
    "hover_text = gcpt_map['Country'] + ': '\n",
    "hover_text = hover_text + gcpt_map['Capacity (MW)'].map('{:,.0f}'.format) + ' MW'\n",
    "# hide extra bit, e.g. 'trace 0'; based on https://plotly.com/python/reference/#scatter-hovertemplate\n",
    "hover_text = hover_text + '<extra></extra>'\n",
    "gcpt_map['hover_text'] = hover_text"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2ad181db-7580-490b-b578-91f896e65575",
   "metadata": {},
   "source": [
    "## Status (upper right)\n",
    "* Data for bar chart capacity by status\n",
    "* From sheet named '2014-2022' (for example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac01cdb0-e835-4ea1-b9b1-756b29ce02b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def status_clean_data(df):\n",
    "    for col in df.columns:\n",
    "        if col not in ['Country', 'Capacity (MW)']:\n",
    "            # make the text lowercase\n",
    "            print(f\"Cleaning col {col}\")\n",
    "            df[col] = df[col].str.lower()\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90fbb104-d847-4d43-a4c4-a1d0e9da9af5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sort_status(df):\n",
    "    \"\"\"\n",
    "    convert column 'Status' to categorical\n",
    "    https://pandas.pydata.org/pandas-docs/stable/user_guide/categorical.html\n",
    "    \"\"\"\n",
    "    \n",
    "    status_order = [\n",
    "        'operating',\n",
    "        'mothballed',\n",
    "        'announced',\n",
    "        'pre-permit',\n",
    "        'permitted',\n",
    "        'construction',\n",
    "        'retired',\n",
    "        'shelved',\n",
    "        'cancelled',\n",
    "    ]\n",
    "    df['Status'] = df['Status'].astype(\n",
    "        CategoricalDtype(status_order, ordered=False)\n",
    "    )    \n",
    "    df = df.sort_values(by=['Country', 'Status', 'Year'])\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c56a44c-3680-4999-bae1-1031dcbe1d95",
   "metadata": {},
   "outputs": [],
   "source": [
    "def status_test_capacity(df, df_init):\n",
    "    \"\"\"Runs at end of status_condense, to check that there was no change in the data.\n",
    "    (Comparing version after condensing the data as it was before condensing the data.)\n",
    "    \n",
    "    There are entries with status NaN in the version of the data before condensing,\n",
    "    because the table prior to that step has a row for each unit, and columns for each year.\n",
    "    (Other distinguishing features for each unit aren't included in this table.)\n",
    "    \n",
    "    If there is no data for a unit for some of the years covered, then we have status NaN for those years.\n",
    "    (Example: It was proposed only in 2018, then the years 2014-2017 have status NaN.)\n",
    "    \"\"\"\n",
    "\n",
    "    df = df.reset_index()\n",
    "        \n",
    "    all_statuses = []\n",
    "    status_min_year = df['Year'].min()\n",
    "    for year in range(status_min_year, max_year+1):\n",
    "        all_statuses += df_init[year].tolist()\n",
    "    all_statuses = list(set(all_statuses))\n",
    "\n",
    "    for sel_status in all_statuses:\n",
    "        print(f\"Testing capacities for {sel_status}\")\n",
    "        for sel_year in range(status_min_year, max_year+1):\n",
    "            sel_init = df_init[df_init[sel_year]==sel_status]\n",
    "            sel_init_sum = sel_init['Capacity (MW)'].sum()\n",
    "\n",
    "            # handle two different formats for df\n",
    "            if 'Status' in df.columns:\n",
    "                sel = df[(df['Year']==sel_year) & (df['Status']==sel_status)]\n",
    "                sel_sum = sel['Capacity (MW)'].sum()\n",
    "                \n",
    "            else:\n",
    "                sel = df[df[sel_year]==sel_status]\n",
    "                sel_sum = sel['Capacity (MW)'].sum()\n",
    "\n",
    "            # compare values\n",
    "            abs_diff = abs(sel_sum - sel_init_sum)\n",
    "            if abs_diff <= 1e-7:\n",
    "                pass\n",
    "\n",
    "            elif abs_diff > 1e-7:\n",
    "                print(\"Error!\" + f\" Capacity difference for {sel_year} & {sel_status}.\")\n",
    "                print(f\"Initial value: {sel_init_sum}\")\n",
    "                print(f\"Current value: {sel_sum}\")\n",
    "            else:\n",
    "                print(\"Unexpected case\")\n",
    "    \n",
    "    # no return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "912a9ab3-3358-4cf5-b3a4-048356900ff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def status_fill_in_missing(df):\n",
    "    \"\"\"\n",
    "    For each country, for each status, fill in zero value if it is missing.\n",
    "    \"\"\"\n",
    "    year_range = range(df['Year'].min(), df['Year'].max() + 1)\n",
    "    statuses = df['Status'].dropna().unique().tolist()\n",
    "    for country in df['Country'].unique().tolist():\n",
    "        for status in statuses:\n",
    "            for year in year_range:\n",
    "                df_sel = df[(df['Year']==year) & (df['Country']==country) & (df['Status']==status)]\n",
    "                if len(df_sel) == 0:\n",
    "                    # there is a missing value; fill it in\n",
    "                    # print(f\"To fill in missing value for {country}, {year}, {status}\") # for db\n",
    "                    # values in dict below must be lists, to avoid error:\n",
    "                    # \"ValueError: If using all scalar values, you must pass an index\"\n",
    "                    new_df = pd.DataFrame.from_dict({\n",
    "                                'Country': [country],\n",
    "                                'Year': [year],\n",
    "                                'Status': [status],\n",
    "                                'Capacity (MW)': [float(0)],\n",
    "                            }, orient='columns')\n",
    "                    df = pd.concat([df, new_df], sort=False)\n",
    "\n",
    "    df = df.sort_values(by=['Country', 'Year', 'Status'])\n",
    "                    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a80c8a1-6ad1-4d89-9856-9f9056057b69",
   "metadata": {},
   "outputs": [],
   "source": [
    "def status_calculate_global_totals(df):    \n",
    "    gcpt_status_all = df.groupby(['Year', 'Status'])[['Capacity (MW)']].sum().reset_index()\n",
    "    gcpt_status_all.insert(0, 'Country', 'all')\n",
    "    gcpt_status_all = sort_status(gcpt_status_all)\n",
    "    \n",
    "    df = pd.concat([gcpt_status_all, df], sort=False)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f95f62ca-3983-4a0d-b0f6-83921739d065",
   "metadata": {},
   "outputs": [],
   "source": [
    "def status_condense(df_arg):\n",
    "    \"\"\"\n",
    "    There are sometimes duplicates, for example if two units in a plant have the exact same capacity and history.\n",
    "    So before setting the index to Country & Capacity, need to get rid of duplicates.\n",
    "    \"\"\"\n",
    "    df = df_arg.copy()\n",
    "    df_init = df_arg.copy()  # for test\n",
    "    \n",
    "    df = df.dropna(how='all')\n",
    "    \n",
    "    df = df.set_index(['Country', 'Capacity (MW)'])\n",
    "    df = df.stack().reset_index()\n",
    "        \n",
    "    df = df.rename(columns={'level_2': 'Year', 0: 'Status'})\n",
    "    \n",
    "    df = df.groupby(['Country', 'Year', 'Status'])[['Capacity (MW)']].sum().reset_index()\n",
    "    df = sort_status(df)\n",
    "\n",
    "    # print(df.columns) # for db\n",
    "    status_test_capacity(df, df_init)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2924d13e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_statuses(gcpt_status_uncondensed):\n",
    "    accepted_statuses = ['announced', 'cancelled', 'construction', 'mothballed', 'operating', 'permitted',  'pre-permit', 'shelved', 'retired']\n",
    "    for col in range(2014, max_year +1):\n",
    "        ser = gcpt_status_uncondensed[col].dropna()\n",
    "        unaccepted = ser[~ser.isin(accepted_statuses)]\n",
    "        if len(unaccepted) > 0:\n",
    "            print(f\"Found unaccepted statuses; len(ser): {len(ser)}\")\n",
    "            print(unaccepted.value_counts())\n",
    "    # no return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3622b343-8929-406a-a963-ec9ecacf08e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "gcpt_status_uncondensed = pd.read_excel(gcpt_dash_xl, sheet_name = f'2014-{max_year}')\n",
    "gcpt_status_uncondensed = status_clean_data(gcpt_status_uncondensed)\n",
    "test_statuses(gcpt_status_uncondensed)\n",
    "\n",
    "gcpt_status = status_condense(gcpt_status_uncondensed)\n",
    "gcpt_status = status_fill_in_missing(gcpt_status)\n",
    "gcpt_status = status_calculate_global_totals(gcpt_status)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "bac2549f-113f-4a9f-9416-3877082b095c",
   "metadata": {},
   "source": [
    "## Age & Technology (lower left)\n",
    "* For bar chart of capacity by age & type\n",
    "* From the sheet 'Plant type and age'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "117a90a5-801f-4630-a9fc-f1fad51d0e74",
   "metadata": {},
   "outputs": [],
   "source": [
    "def age_read_and_clean(gcpt_dash_xl):\n",
    "    gcpt_age = pd.read_excel(gcpt_dash_xl, sheet_name = 'Plant type and age')\n",
    "    \n",
    "    # change capitalization of 'Ultra-Supercritical' to 'Ultra-supercritical'\n",
    "    gcpt_age['Combustion technology'] = gcpt_age['Combustion technology'].replace(\n",
    "        'Ultra-Supercritical', 'Ultra-supercritical'\n",
    "    )\n",
    "    \n",
    "    return gcpt_age\n",
    "\n",
    "def age_condense_data(df):\n",
    "    print(len(df))\n",
    "\n",
    "    # bin by decade\n",
    "    for row in df.index:\n",
    "        age = df.at[row, 'Plant Age']\n",
    "        if age < 10:\n",
    "            df.at[row, 'decade'] = '0-9 years'\n",
    "        elif age >= 10 and age < 20:\n",
    "            df.at[row, 'decade'] = '10-19 years'\n",
    "        elif age >= 20 and age < 30:\n",
    "            df.at[row, 'decade'] = '20-29 years'\n",
    "        elif age >= 30 and age < 40:\n",
    "            df.at[row, 'decade'] = '30-39 years'\n",
    "        elif age >= 40 and age < 50:\n",
    "            df.at[row, 'decade'] = '40-49 years'\n",
    "        elif age >= 50:\n",
    "            df.at[row, 'decade'] = '50+ years'\n",
    "        else:\n",
    "            print(\"Error!\" + f\" Issue with age for row {row}: {age}\")\n",
    "\n",
    "    df = df.groupby(['Country', 'decade', 'Combustion technology'])[['Capacity (MW)']].sum()\n",
    "    df = df.reset_index()\n",
    "    \n",
    "    # unstack, then fill in zeros\n",
    "    df = df.set_index(['Country', 'decade', 'Combustion technology']).unstack()\n",
    "    df = df.droplevel(0, axis=1)\n",
    "    \n",
    "    for col in df.columns:\n",
    "        df[col] = df[col].fillna(0)\n",
    "\n",
    "    df = df.reset_index()\n",
    "    df.columns.name = ''\n",
    "    \n",
    "    print(len(df))\n",
    "    \n",
    "    return df\n",
    "\n",
    "def age_calculate_global_totals(df):\n",
    "\n",
    "    technologies = ['CFB', 'IGCC', 'Subcritical', 'Supercritical', 'Ultra-supercritical', 'Unknown']\n",
    "    \n",
    "    gcpt_age_all = df.groupby('decade')[technologies].sum().reset_index()\n",
    "    gcpt_age_all.insert(0, 'Country', 'all')\n",
    "\n",
    "    df = pd.concat([gcpt_age_all, df], sort=False)\n",
    "\n",
    "    return df\n",
    "\n",
    "def age_fill_in_missing_decades(df):\n",
    "    decade_list = [\n",
    "        '0-9 years',\n",
    "        '10-19 years',\n",
    "        '20-29 years',\n",
    "        '30-39 years',\n",
    "        '40-49 years',\n",
    "        '50+ years',\n",
    "    ]\n",
    "    for country_sel in gcpt_country_list:\n",
    "        for decade_sel in decade_list:\n",
    "            df_sel = df[(df['Country']==country_sel) & (df['decade']==decade_sel)]\n",
    "            if len(df_sel) == 0:\n",
    "                new_df = pd.DataFrame.from_dict({\n",
    "                        'Country': country_sel,\n",
    "                        'decade': decade_sel,\n",
    "                        'CFB': [float(0)],\n",
    "                        'IGCC': [float(0)],\n",
    "                        'Subcritical': [float(0)],\n",
    "                        'Supercritical': [float(0)],\n",
    "                        'Ultra-supercritical': [float(0)],\n",
    "                        'Unknown': [float(0)],\n",
    "                    }, orient='columns')\n",
    "                df = pd.concat([df, new_df], sort=False)\n",
    "            elif len(df_sel) == 1:\n",
    "                pass\n",
    "\n",
    "            elif len(df_sel) > 1:\n",
    "                print(\"Error!\")\n",
    "            else:\n",
    "                print(\"Error! (of another kind)\")\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "gcpt_age = age_read_and_clean(gcpt_dash_xl)\n",
    "gcpt_age = age_condense_data(gcpt_age)\n",
    "gcpt_age = age_calculate_global_totals(gcpt_age)\n",
    "gcpt_age = age_fill_in_missing_decades(gcpt_age)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6b27d80-b3a7-486d-a7e2-1789399360c3",
   "metadata": {},
   "source": [
    "## Additions & retirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81a4dd8b-abac-4885-bdef-d17e94bc59c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data for bar chart additions and retirements (lower-right): sheet '2000-2022' (for example)\n",
    "# no condensing needed, but need to unstack\n",
    "\n",
    "additions_max_year = 2022\n",
    "\n",
    "def add_unstack(df):\n",
    "    df = df.set_index(['Country', 'Year', 'Status'])\n",
    "    df = df.unstack(-1)\n",
    "    df = df.droplevel(0, axis=1)\n",
    "    df = df.reset_index()\n",
    "    df = df.rename(columns={\n",
    "        'Operating': 'Added (MW)', \n",
    "        'Retired': 'Retired (MW)'\n",
    "    })\n",
    "        \n",
    "    return df\n",
    "\n",
    "def add_missing_countries(df):\n",
    "    # add any missing countries, to make sure that all countries in gcpt_country_list are in gcpt_map\n",
    "    missing_countries = [x for x in gcpt_country_list if x not in gcpt_add['Country'].tolist()]\n",
    "    print(f\"Show any countries missing (which will be added below): {missing_countries}\")\n",
    "    \n",
    "    for year in range(\n",
    "        int(gcpt_add['Year'].min()), \n",
    "        int(gcpt_add['Year'].max())+1):\n",
    "\n",
    "        new_df = pd.DataFrame.from_dict({\n",
    "                'Country': missing_countries,\n",
    "                'Year': year,\n",
    "                'Added (MW)': [float(0)]*len(missing_countries),\n",
    "                'Retired (MW)': [float(0)]*len(missing_countries),\n",
    "            }, orient='columns')\n",
    "        df = pd.concat([df, new_df], sort=False)\n",
    "    return df\n",
    "\n",
    "def add_calculate_global_totals(df):\n",
    "    gcpt_add_all = df.groupby('Year')[['Added (MW)', 'Retired (MW)', 'Net added (MW)']].sum().reset_index()\n",
    "    gcpt_add_all.insert(0, 'Country', 'all')\n",
    "    df = pd.concat([gcpt_add_all, df], sort=False)\n",
    "    \n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6beaa60e",
   "metadata": {},
   "outputs": [],
   "source": [
    "gcpt_add = pd.read_excel(gcpt_dash_xl, sheet_name = f'2000-{additions_max_year}')\n",
    "\n",
    "gcpt_add = add_unstack(gcpt_add)\n",
    "\n",
    "gcpt_add = add_missing_countries(gcpt_add)\n",
    "\n",
    "gcpt_add['Net added (MW)'] = gcpt_add['Added (MW)'].sub(gcpt_add['Retired (MW)'])\n",
    "gcpt_add = add_calculate_global_totals(gcpt_add)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab768331-a954-4e3f-b0ae-6f627b3028c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TEST: check that there are not any rows with NaNs for 'Net added'\n",
    "test = gcpt_add[gcpt_add['Net added (MW)'].isna()]\n",
    "if len(test) > 0:\n",
    "    print(\"Error!\" + f\" There were rows with value NaN for 'Net added (MW)'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccbd2a7c-639e-4daf-a36e-305b2cf317e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export to various sheets of one Excel file by creating ExcelWriter object\n",
    "template_name = gcpt_dash_file.split('.xlsx')[0]\n",
    "save_timestamp = time.strftime('%Y-%m-%d_%H%M', time.localtime())\n",
    "file_name = f'{template_name} - processed for Dash {save_timestamp}.xlsx'\n",
    "with pd.ExcelWriter(gcpt_dash_path + file_name) as writer:\n",
    "    gcpt_map.to_excel(writer, sheet_name='map', index=False)  \n",
    "    gcpt_status.to_excel(writer, sheet_name='status', index=False)\n",
    "    gcpt_age.to_excel(writer, sheet_name='age', index=False)\n",
    "    gcpt_add.to_excel(writer, sheet_name='additions', index=False)\n",
    "    print(f\"Saved to file: {file_name}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_gem_2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "838faa36e87386bb9f30d7573e0ee96788518f158b84035d7a56816bd47c3a5c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
